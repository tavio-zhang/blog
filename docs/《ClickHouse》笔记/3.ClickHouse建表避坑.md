---
title: ClickHouse建表避坑
date: 2022-06-25 19:44:05
permalink: /pages/ed208a/
categories:
  - 《ClickHouse》笔记
tags:
  - ClickHouse建表避坑
author: 
  name: Tavio
  link: https://github.com/tavio-zhang
---

在 ClickHouse 中，建表是整个数据架构的基石，而分区键（PARTITION BY）、排序键（ORDER BY）、主键（PRIMARY KEY）的设计，直接决定了后续查询性能、存储效率和运维成本。很多初学者甚至资深开发者，都会在这三个“键”的选择上踩坑——比如把主键当唯一约束用、分区键粒度太细导致元数据爆炸、排序键设计不合理让查询全表扫描。

## 一、先厘清：三个“键”的核心作用与本质区别

首先要明确：ClickHouse 的分区键、排序键、主键，和 MySQL、PostgreSQL 等传统关系型数据库的概念完全不同，切勿直接套用经验。三者的核心定位和作用如下：

| 参数                | 核心作用                          | 本质特征                                      | 关键影响                                      |
| ------------------- | --------------------------------- | --------------------------------------------- | --------------------------------------------- |
| 分区键（PARTITION BY） | 数据分片存储，实现“分区裁剪”      | 逻辑上的数据集划分，按分区独立管理数据（可独立删除、TTL） | 查询时能否快速过滤无效数据；元数据管理成本    |
| 排序键（ORDER BY）     | 决定数据在磁盘上的物理存储顺序    | 数据按排序键有序存储，支撑稀疏索引和查询跳过  | 查询扫描范围大小；数据压缩率；合并（Merge）效率 |
| 主键（PRIMARY KEY）    | 构建稀疏索引，快速定位数据块      | 默认是排序键的前缀（可自定义），非唯一约束，仅用于索引定位 | 数据定位速度；索引存储开销                    |

核心结论：**分区键负责“大范围数据过滤”，排序键负责“小范围数据有序与跳过”，主键是排序键的“索引入口”**。三者协同决定了查询性能的上限。

## 二、分区键：粒度是关键，别太细也别太粗

分区键的核心价值是“分区裁剪”——查询时如果带上分区键条件，ClickHouse 会直接跳过不相关的分区，只扫描目标分区数据，大幅减少I/O开销。但分区键的粒度设计是重中之重，过细或过粗都会踩坑。

### 1. 选择原则：按“时间+业务维度”组合，控制单分区大小

最通用、最安全的选择是 **“时间字段为主，业务维度为辅”**，同时满足“单分区大小10-100GB”“分区数量不超过1000”两个核心指标（ClickHouse 对元数据的管理效率在1000个分区以内最优）。

常见选择优先级：
1.  高频场景：按日期/月份分区（适用于日志、监控、行为等时间序列数据）
    示例：`PARTITION BY toYYYYMMDD(event_time)`（按天）、`PARTITION BY toYYYYMM(event_time)`（按月）
2.  低频场景：按业务维度+时间分区（适用于数据量较小的业务表）
    示例：`PARTITION BY (business_line, toYYYYMM(event_time))`（业务线+月）
3.  特殊场景：固定分区（适用于小表、配置表）
    示例：`PARTITION BY 1`（所有数据在一个分区）

### 2. 避坑指南：这3个错误千万别犯

- **坑1：分区粒度太细（如按小时分区）**
  后果：如果数据量较大，会导致分区数量暴增（一天24个分区，一年8760个），元数据管理压力大，合并（Merge）线程忙不过来，查询时扫描大量小分区反而变慢。
  避坑：只有当单小时数据量达到10GB以上，且查询需要按小时过滤时，才考虑按小时分区；否则优先按天/月。
- **坑2：分区粒度太粗（如按年分区）**
  后果：单分区数据量过大（可能达TB级），查询时无法有效裁剪，相当于全表扫描；且删除过期数据时（如删除1年前数据），单分区删除耗时久，影响集群性能。
  避坑：单分区大小超过100GB时，必须细化粒度（比如从按年改为按月）。
- **坑3：用高频离散字段当分区键（如user_id、device_id）**
  后果：每个分区只有少量数据（甚至单行），分区数量爆炸，元数据崩溃，查询性能极差。
  避坑：绝对禁止用高频离散字段单独当分区键；若需按用户维度过滤，优先放在排序键中。

### 3. 实战案例：不同数据量的分区键选择

- 案例1：用户行为日志（日均100GB）
  选择：`PARTITION BY toYYYYMMDD(event_time)`（按天分区，单分区100GB左右，一年365个分区，符合要求）
- 案例2：设备监控数据（日均5GB）
  选择：`PARTITION BY toYYYYMM(event_time)`（按月分区，单分区150GB左右，一年12个分区，管理成本低）
- 案例3：业务配置表（总数据10MB）
  选择：`PARTITION BY 1`（单分区，无需裁剪，简化管理）

## 三、排序键：查询导向设计，把“高频过滤字段”放前面

排序键是 ClickHouse 性能优化的核心——数据按排序键物理有序存储，一方面能提升压缩率（有序数据压缩比更高），另一方面能支撑“稀疏索引跳过”：查询时通过排序键的索引标记，直接跳过不满足条件的数据块，减少扫描范围。

关键原则：**排序键的设计必须“以查询为导向”，把高频过滤、分组、排序字段放在前面**，且字段数量不宜过多（建议不超过4个，过多会降低索引效率）。

### 1. 选择原则：高频字段优先，前缀匹配优先

ClickHouse 的查询优化器对排序键的“前缀匹配”支持最好，因此排序键的字段顺序优先级为：
1.  第一优先级：查询中最常用的 `WHERE` 过滤字段（如 user_id、order_id、status）
2.  第二优先级：查询中常用的 `GROUP BY` 分组字段（如 business_line、region）
3.  第三优先级：查询中常用的 `ORDER BY` 排序字段（如 event_time、amount）

示例：某电商订单表，高频查询场景是“按用户ID查询订单”“按订单状态+时间统计”，排序键设计为：
`ORDER BY (user_id, status, create_time)`

### 2. 避坑指南：这4个误区要避开

- **坑1：排序键字段过多（如5个以上）**
  后果：稀疏索引的粒度变粗，跳过效率降低；同时增加数据合并时的排序开销，影响写入性能。
  避坑：只保留前3-4个高频字段，低频字段不放入排序键。
- **坑2：排序键与查询过滤字段不匹配**
  后果：查询无法利用排序键的跳过功能，只能全分区扫描，性能极差。
  示例：排序键是 `(create_time, user_id)`，但高频查询是 `WHERE user_id = 123`（非前缀字段），无法触发跳过。
  避坑：调整排序键顺序为 `(user_id, create_time)`，确保高频过滤字段在排序键前缀。
- **坑3：把低基数字段放前面**
  后果：低基数字段（如 status，只有“待支付”“已支付”等几个值）的区分度低，排序后数据分布集中，跳过效率差。
  避坑：高基数字段（如 user_id、order_id）优先放在排序键前面，低基数字段放后面。
- **坑4：忽略数据压缩率**
  后果：无序数据或低重复度数据的压缩比极低，增加存储成本。
  避坑：时间字段、枚举字段等重复度高的字段，可适当放在排序键中，提升压缩率（如 create_time 放在高基数字段之后）。

### 3. 实战案例：不同查询场景的排序键设计

- 场景1：用户行为日志（高频查询：按用户ID+日期过滤）
  排序键：`ORDER BY (user_id, event_time)`（高基数user_id在前，时间字段在后，兼顾过滤和压缩）
- 场景2：商品销售统计（高频查询：按商品ID+销售日期分组）
  排序键：`ORDER BY (product_id, sale_date)`（商品ID过滤，销售日期分组，匹配查询逻辑）
- 场景3：实时监控指标（高频查询：按指标类型+时间排序）
  排序键：`ORDER BY (metric_type, collect_time)`（指标类型过滤，时间排序，提升查询跳过效率）

## 四、主键：默认前缀即可，别当“唯一约束”用

ClickHouse 的主键和传统数据库的主键完全不同——它不具备“唯一约束”功能，仅用于构建“稀疏索引”，帮助快速定位数据块。默认情况下，主键是排序键的前缀（如果不指定主键，主键=排序键）。

### 1. 选择原则：简化优先，复用排序键前缀

大多数场景下，**无需手动指定主键**，直接使用默认值（主键=排序键）即可。只有当排序键字段较多，且高频查询仅依赖前1-2个字段时，才需要手动指定主键（取排序键的前缀），减少索引存储开销。

示例：排序键是 `(user_id, status, create_time)`，高频查询仅依赖 `user_id` 过滤，可手动指定主键：
`PRIMARY KEY (user_id)`

### 2. 避坑指南：这2个错误最致命

- **坑1：把主键当唯一约束用**
  后果：ClickHouse 不会检查主键的唯一性，插入重复主键的数据会直接存储，导致数据不一致。
  避坑：如果需要去重，应使用 `ReplacingMergeTree` 引擎，通过排序键+版本列实现去重，而非依赖主键。
- **坑2：主键不是排序键的前缀**
  后果：ClickHouse 不支持主键非排序键前缀的设计，建表会直接报错。
  避坑：主键必须是排序键的子集且为前缀，例如排序键是 `(a,b,c)`，主键可设为 `(a)` 或 `(a,b)`，但不能是 `(b,c)` 或 `(a,c)`。

## 五、三者协同设计：实战建表案例拆解

前面讲了单个键的选择，实际建表时需要三者协同。下面以“电商订单表”和“用户行为日志表”两个典型场景，完整拆解建表语句和设计思路。

### 1. 场景1：电商订单表（MergeTree 引擎）

核心需求：
- 数据量：日均50GB，按天分区单分区50GB（符合10-100GB要求）
- 高频查询：按用户ID查订单、按订单状态+日期统计、按订单ID查详情
- 运维需求：保留1年数据，按月删除过期分区

建表语句：
```sql

CREATE TABLE order_table (
  order_id UInt64 COMMENT '订单ID',
  user_id UInt64 COMMENT '用户ID',
  status Enum8('pending'=1, 'paid'=2, 'shipped'=3, 'completed'=4, 'cancelled'=5) COMMENT '订单状态',
  amount Float64 COMMENT '订单金额',
  create_time DateTime COMMENT '创建时间',
  pay_time DateTime COMMENT '支付时间',
  province String COMMENT '省份'
) ENGINE = MergeTree()
PARTITION BY toYYYYMMDD(create_time)  -- 按天分区（单分区50GB，一年365个分区）
ORDER BY (user_id, status, create_time, order_id)  -- 排序键：高频过滤字段在前
PRIMARY KEY (user_id)  -- 主键取排序键前缀，减少索引开销
TTL create_time + INTERVAL 365 DAY DELETE;  -- 数据保留1年
```

设计思路：
- 分区键：按天分区，匹配订单数据的时间特性，便于按日期裁剪和删除过期数据；
- 排序键：user_id（高频过滤）→ status（高频统计）→ create_time（时间排序）→ order_id（唯一标识），完全匹配查询场景；
- 主键：仅保留user_id（高频过滤字段），减少稀疏索引的存储开销。

### 2. 场景2：用户行为日志表（ReplicatedMergeTree 引擎，高可用）

核心需求：
- 数据量：日均100GB，按天分区单分区100GB；
- 高频查询：按用户ID+行为类型+日期过滤，统计用户行为次数；
- 运维需求：高可用（副本），保留90天数据。

建表语句：

```sql
CREATE TABLE user_behavior_log (
  user_id UInt64 COMMENT '用户ID',
  behavior_type Enum8('click'=1, 'view'=2, 'purchase'=3, 'share'=4) COMMENT '行为类型',
  event_time DateTime COMMENT '行为时间',
  page String COMMENT '页面',
  device_id String COMMENT '设备ID'
) ENGINE = ReplicatedMergeTree(
  '/clickhouse/tables/{shard}/user_behavior_log',  -- ZooKeeper路径
  '{replica}'  -- 副本标识
)
PARTITION BY toYYYYMMDD(event_time)  -- 按天分区（单分区100GB，符合要求）
ORDER BY (user_id, behavior_type, event_time)  -- 排序键：匹配高频查询过滤逻辑
TTL event_time + INTERVAL 90 DAY DELETE;  -- 数据保留90天
```

设计思路：
- 分区键：按天分区，适配日志数据的时间序列特性，便于快速裁剪；
- 排序键：user_id（高频过滤）→ behavior_type（统计维度）→ event_time（时间排序），完全匹配查询场景，同时提升数据压缩率；
- 主键：使用默认值（=排序键），无需额外优化，简化配置；
- 引擎：ReplicatedMergeTree 保障高可用，适配生产环境需求。

## 六、总结：建表避坑核心口诀

最后用几句口诀总结核心要点，帮你快速记忆：
1.  分区键：时间为主，粒度适中，10-100GB/区，分区数不超千；
2.  排序键：查询导向，高频在前，前缀匹配，字段不超四；
3.  主键：默认前缀，无需冗余，不做唯一，简化优先；
4.  三协同：分区裁剪定范围，排序跳过缩粒度，主键索引提速度。

其实 ClickHouse 建表的核心逻辑很简单——**所有设计都围绕“减少查询扫描范围”展开**。只要记住“以查询为导向”，结合数据量和业务场景，就能避开大部分坑。如果建表后发现查询性能差，优先检查这三个键的设计，往往能事半功倍。