---
title: ClickHouse性能怪兽
date: 2022-06-11 21:24:11
permalink: /pages/d1c3a5/
categories:
  - 《ClickHouse》笔记
tags:
  - ClickHouse性能怪兽
author: 
  name: Tavio
  link: https://github.com/tavio-zhang
---

在大数据分析领域，“快速”永远是核心诉求之一。当你面对每日 10 亿+ 条广告日志、用户行为数据，需要秒级返回查询结果时，传统数据库往往力不从心。而 ClickHouse，这个由俄罗斯 Yandex 公司为 Yandex.Metrica（世界第三大网络分析平台）打造的列式存储数据库，正是为解决“海量数据快速分析”而生的“性能怪兽”。

## 一、ClickHouse 核心定义：不止是“数据库”，更是“分析引擎”

官方对 ClickHouse 的定位是：**一个用于联机分析处理（OLAP）的列式存储数据库管理系统（DBMS）**。

这里有两个关键信息需要拆解：
1.  **OLAP 场景定位**：专门针对“读多写少”的分析场景，比如数据报表、多维分析、用户画像、广告效果分析等。区别于 OLTP 场景（比如电商交易、金融支付）的“高频小事务”，OLAP 场景的特点是“海量数据批量读写+复杂聚合查询”。
2.  **列式存储核心**：这是 ClickHouse 性能强悍的根本原因，后续会详细拆解。简单说，传统数据库（MySQL、PostgreSQL）是行式存储，而 ClickHouse 是列式存储，两者在“分析海量数据”时的效率天差地别。

一句话总结：ClickHouse 不是为“实时交易”设计的，而是为“海量数据快速分析”而生的专用引擎。

## 二、性能核心：列式存储 vs 行式存储，差在哪？

要理解 ClickHouse 的快，必须先搞懂“列式存储”和传统“行式存储”的本质区别。我们用一个实际场景举例：广告日志数据，包含字段「日期（dt）、素材ID（material_id）、平台（platform）、曝光量（impressions）、点击量（clicks）」。

### 1. 行式存储（比如 MySQL）：按“行”存储数据

行式存储会把一行数据的所有字段打包存在一起，比如：
「2026-01-13, MAT_001, TikTok, 10000, 500」「2026-01-13, MAT_002, Facebook, 20000, 1200」...

当我们需要分析“2026-01-13 各平台的总曝光量”时，行式存储的问题就来了：
- 必须读取每一行的所有字段（包括不需要的 material_id、clicks），再过滤出需要的 dt、platform、impressions 字段；
- 数据读取量极大，比如 10 亿条数据，每条 5 个字段，需要读取 50 亿个字段的数据，IO 开销巨大。

### 2. 列式存储（ClickHouse）：按“列”存储数据

列式存储会把同一个字段的所有数据打包存在一起，比如：
dt 列：「2026-01-13, 2026-01-13, ...」
platform 列：「TikTok, Facebook, ...」
impressions 列：「10000, 20000, ...」

同样分析“2026-01-13 各平台的总曝光量”，列式存储的优势直接拉满：
- 只需要读取 3 个需要的列（dt、platform、impressions），不需要的列（material_id、clicks）完全不读，数据读取量减少 40%+；
- 同一列的数据类型相同，可进行高效压缩（比如 dt 列都是日期，压缩比可达 10:1 以上），进一步减少 IO 开销；
- 聚合计算（sum、count）时，可直接对列数据批量处理，CPU 缓存命中率更高，计算速度更快。

### 3. 核心差异对比表

| 对比维度 | 行式存储（MySQL） | 列式存储（ClickHouse） |
|----------|-------------------|------------------------|
| 存储方式 | 按行打包存储，一行数据所有字段连续 | 按列打包存储，同一字段数据连续 |
| 读取效率（分析场景） | 低，需读取无关字段，IO 开销大 | 高，只读取需要的列，配合压缩进一步降低 IO |
| 压缩效率 | 低，字段类型多样，难以高效压缩 | 高，同列数据类型一致，压缩比可达 5:1~10:1 |
| 适用场景 | OLTP（实时交易、高频小事务） | OLAP（海量数据分析、报表、多维查询） |

## 三、ClickHouse 核心特性：不止快，还很灵活

列式存储是 ClickHouse 的“基础盘”，但它的强大还源于一系列针对性优化的核心特性：

### 1. 高吞吐写入，低延迟查询
- 写入性能：支持批量写入，单机可轻松支撑每秒 10 万+ 条数据写入（比如广告日志的实时采集），写入时不锁表，不影响查询；
- 查询性能：百万级数据聚合查询秒级返回，亿级数据查询耗时通常在 1~10 秒内（比如查询近 7 天各广告平台的总点击量）。

### 2. 强大的 MergeTree 引擎家族
MergeTree 是 ClickHouse 的核心表引擎，专为海量数据存储和分析设计，衍生出多个功能各异的子引擎，覆盖不同分析场景：
- MergeTree：基础引擎，支持分区、排序、TTL，适用于大多数无需特殊处理的分析场景；
- ReplacingMergeTree：支持数据去重，适合广告素材、用户画像等需要精准去重的场景；
- SummingMergeTree：自动聚合相同排序键的数值字段，适合广告指标（曝光、点击、花费）的预聚合；
- AggregatingMergeTree：支持更复杂的聚合（比如 distinct count、group by 多字段），适合多维分析场景。

### 3. 灵活的分区与排序设计
- 分区键（PARTITION BY）：可按日期、地区等字段分区，比如广告数据按天分区，查询时可通过分区过滤（比如只查 2026-01-13 的数据），避免全表扫描；
- 排序键（ORDER BY）：按核心查询字段排序，比如广告数据按「platform + material_id」排序，大幅提升聚合查询效率。

### 4. 分布式扩展能力
支持单机部署，也支持分布式集群部署。通过分片（Shard）将数据分散存储在多个节点，查询时可并行计算，线性提升处理能力，轻松应对 PB 级数据。

### 5. 丰富的查询语法与函数
兼容标准 SQL，支持复杂的聚合函数（sum、count、avg、distinct count）、窗口函数、数组函数等，比如广告分析中常用的「计算各平台 CTR（点击率=点击量/曝光量）」「按小时统计曝光趋势」等需求，都能通过简单 SQL 实现。

## 四、ClickHouse 适用场景 vs 不适用场景：别用错地方！

ClickHouse 是“专用工具”，不是“万能工具”，找对场景才能发挥它的最大价值。

### 1. 适用场景（OLAP 核心场景）
- 日志/行为分析：广告日志、用户行为日志（浏览、点击、购买）、服务器日志的存储与分析；
- 数据报表：业务监控报表、广告效果报表、运营数据报表（日报、周报、月报）；
- 多维分析：支持按任意维度（时间、地区、平台、用户群体）切片分析，比如“近 7 天 TikTok 平台 3C 类商品的广告 ROI”；
- 用户画像：存储用户标签数据，支持用户群体筛选、画像分析（比如“25-30 岁女性用户中点击过美妆广告的人数”）。

### 2. 不适用场景（别硬扛！）
- 实时交易（OLTP）：比如电商下单、金融支付、用户注册等需要强事务（ACID）、高频单条写入/更新的场景；ClickHouse 不支持事务，单条更新/删除性能极差；
- 高并发小查询：比如每秒 10 万+ 次的单条数据查询（比如根据用户 ID 查详情）；ClickHouse 适合批量聚合查询，高并发小查询会导致性能下降；
- 需要频繁更新/删除：比如用户余额、订单状态等需要实时更新的数据；ClickHouse 设计初衷是“写入后很少修改”，频繁更新会产生大量碎片，影响性能。

## 五、实际落地案例：广告效果分析平台

结合我之前的实践经验，用 ClickHouse 搭建广告效果分析平台的核心架构如下，让你直观看到它的落地方式：

### 1. 业务需求
每日处理 10 亿+ 条广告曝光/点击日志，支持：
- 单天/近 7 天/近 30 天广告素材数据查询；
- 按平台、商品类目、素材类型等维度聚合分析；
- 秒级返回报表结果，支撑 500+ 广告主的实时查询需求。

### 2. 技术选型
- 数据采集：Flink 实时采集 Kafka 中的广告日志；
- 数据存储：ClickHouse 单机部署（初期），后续按平台分片扩展为分布式集群；
- 表引擎：核心表用 ReplacingMergeTree（广告素材去重），预聚合表用 SummingMergeTree（提前计算近 7 天/30 天指标）；
- 分区/排序：按日期（dt）分区，按「platform + material_id + product_id」排序。

### 3. 建表示例（核心表）
```sql
-- 广告投放素材原始明细表（ReplacingMergeTree 去重）
CREATE TABLE ad_foreign_material_detail (
    dt Date COMMENT '广告投放日期（分区键）',
    material_id String COMMENT '广告素材唯一ID',
    product_id String COMMENT '商品SKU',
    platform String COMMENT '海外平台（TikTok/Facebook等）',
    impressions UInt64 COMMENT '单日曝光量',
    clicks UInt64 COMMENT '单日点击量',
    update_time DateTime COMMENT '素材更新时间（去重版本列）'
) ENGINE = ReplacingMergeTree(update_time)
PARTITION BY dt
ORDER BY (dt, material_id, product_id, platform)
TTL dt + INTERVAL 90 DAY DELETE;
```

### 4. 落地效果
- 写入性能：每秒 15 万+ 条广告日志写入，无延迟；
- 查询性能：单天数据查询 50ms 内返回，近 7 天预聚合数据查询 20ms 内返回；
- 资源占用：单机（8C 16G）即可支撑每日 10 亿条数据的存储与分析，性价比极高。

## 六、总结：ClickHouse 核心价值是什么？

ClickHouse 的核心价值，是「用极低的成本（硬件、开发），实现海量数据的快速分析」。它不是对传统数据库的“替代”，而是对 OLAP 场景的“专用优化”。

如果你遇到以下问题，不妨试试 ClickHouse：
1. MySQL/PostgreSQL 分析海量数据时查询太慢（比如 1 亿条数据查询要几分钟）；
2. 需要搭建数据报表平台，要求秒级返回聚合结果；
3. 处理日志、行为数据，需要多维切片分析。